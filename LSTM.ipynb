{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TP3aSP2cK-QT"
   },
   "source": [
    "In this code demo, we will see how we can build LSTM using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-0Kp9PSNCw_b",
    "outputId": "90db7c49-6863-4556-85e7-c5ab3d1b1fa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "VEni0jEACwJo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "BASE_DIR=\"/content/gdrive/MyDrive/RNN-LSTM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "dwxPCzZ3CwJv"
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(os.path.join(BASE_DIR,'headlines.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jrWHEVkqCwJw",
    "outputId": "78262081-09ec-4af8-caa2-0a85fcccc098"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>226435</td>\n",
       "      <td>Google+ rolls out 'Stories' for tricked out ph...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>356684</td>\n",
       "      <td>Dov Charney's Redeeming Quality</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>246926</td>\n",
       "      <td>White God adds Un Certain Regard to the Palm Dog</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>318360</td>\n",
       "      <td>Google shows off Androids for wearables, cars,...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>277235</td>\n",
       "      <td>China May new bank loans at 870.8 bln yuan</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                              TITLE CATEGORY\n",
       "0  226435  Google+ rolls out 'Stories' for tricked out ph...        t\n",
       "1  356684                    Dov Charney's Redeeming Quality        b\n",
       "2  246926   White God adds Un Certain Regard to the Palm Dog        e\n",
       "3  318360  Google shows off Androids for wearables, cars,...        t\n",
       "4  277235         China May new bank loans at 870.8 bln yuan        b"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "ofabgzHSCwJy"
   },
   "outputs": [],
   "source": [
    "## We will create a classifier using embedding layer and Recurrent layer\n",
    "X=train['TITLE']\n",
    "y=train['CATEGORY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "F0JqX1qhCwJz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "m51GVRw6CwJz"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "cDrPCVkICwJ0"
   },
   "outputs": [],
   "source": [
    "enc=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "ZF98rlN7CwJ1"
   },
   "outputs": [],
   "source": [
    "y_train=enc.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJoXqvpDCwJ2",
    "outputId": "096b61e3-c7fe-46b5-c354-538ccf368c54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['b', 'e', 'm', 't'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTrg2VvOCwJ3",
    "outputId": "5c725ae0-6190-401b-ad5b-01d37b8b045b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 3, ..., 3, 1, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "WRv_prVgCwJ4"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "vbNoylKbCwJ5"
   },
   "outputs": [],
   "source": [
    "seq_len=16\n",
    "max_words=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "ONHBs4ObCwJ6"
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=max_words)\n",
    "### Split the text into words and assign an integer id\n",
    "tokenizer.fit_on_texts(X_train.tolist())\n",
    "## Create a sequence for each entry in the title column\n",
    "sequence=tokenizer.texts_to_sequences(X_train.tolist())\n",
    "## Pad the sequences\n",
    "train_features=pad_sequences(sequence,maxlen=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoGUcIRCCwJ7",
    "outputId": "90c83511-e5bb-4b47-a20b-f1234f86889f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  142, 1562, 8052],\n",
       "       [   0,    0,    0, ...,    4, 1671,  525],\n",
       "       [   0,    0,    0, ..., 5370,    6,   47],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 4732, 1042,  359],\n",
       "       [   0,    0,    0, ...,   46,   41,   80],\n",
       "       [   0,    0,    0, ..., 2953, 6426, 2189]], dtype=int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pY9iuUjZCwJ8",
    "outputId": "64d59c43-8a2e-43a1-abe8-ff7a2eb5c801"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168967, 16)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFYqtAhpCwJ8",
    "outputId": "603e9f5f-8212-49d8-a5d9-fd417b02c265"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  113,    2,   31],\n",
       "       [   0,    0,    0, ...,    4, 4018, 3115],\n",
       "       [   0,    0,    0, ...,  375, 5948, 4400],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   11,  157, 1648],\n",
       "       [   0,    0,    0, ...,   97,   76,    7],\n",
       "       [   0,    0,    0, ...,  310, 3979, 5986]], dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create test features\n",
    "sequence=tokenizer.texts_to_sequences(X_test.tolist())\n",
    "test_features=pad_sequences(sequence,maxlen=seq_len)\n",
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0sc5cHWQCwJ9",
    "outputId": "6a55d813-882b-4941-8f5b-e68ef7aeaf62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42242, 16)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "i9QNblWBCwJ9"
   },
   "outputs": [],
   "source": [
    "## Convert y_test and y_train to one hot encoded vector\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "6shmThUfCwJ-"
   },
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDIECrihCwJ-",
    "outputId": "5b558bbb-2826-4ee3-aa8b-7afe0d1da11b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "dZDI-_W9CwJ_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fU80RuZ9CwJ_",
    "outputId": "ca203328-f210-43aa-e97a-55c730e14284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 16.805164337158203 seconds to load glove word vectors\n"
     ]
    }
   ],
   "source": [
    "### Read glove word vectors\n",
    "t0=time.time()\n",
    "embedding_index={}\n",
    "con=open(os.path.join(BASE_DIR,'glove.6B.100d.txt'),encoding='utf-8')\n",
    "for line in con:\n",
    "    values=line.split()\n",
    "    word=values[0]\n",
    "    vector=np.asarray(values[1:],dtype='float32')\n",
    "    embedding_index[word]=vector\n",
    "con.close()\n",
    "t1=time.time()\n",
    "print(\"Took {} seconds to load glove word vectors\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "tlSuAs2sCwKA"
   },
   "outputs": [],
   "source": [
    "## Now create an embedding matrix for 10000 words in our corpus\n",
    "embedding_weight_matrix=np.zeros((max_words,100))\n",
    "for word,i in tokenizer.word_index.items():\n",
    "    if i < max_words:\n",
    "        vector=embedding_index.get(word)\n",
    "        if vector is not None:\n",
    "            embedding_weight_matrix[i]=vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbBhaxavL-x1"
   },
   "source": [
    "Now, I will start assembling my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y55yzWR6UBVK"
   },
   "source": [
    "LSTM model using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktCbUTvTUrcM"
   },
   "source": [
    "Now beside the dense layers and the embedding layer I will also use LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "fsjJeChRUC_D"
   },
   "outputs": [],
   "source": [
    "## Now we will assemble the model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding,LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "yoR7pf_4UdQ2"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(input_dim=max_words,output_dim=100,\n",
    "                    weights=[embedding_weight_matrix],\n",
    "                    input_length=seq_len))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bhu5YO7uU5EI"
   },
   "source": [
    "My first layer in the model is an embedding layer, where the input dimensional is equal to the maximum vocabulary allowed which is 10,000. The output dimension is going to be hundred because I'm using word vectors that have a dimension 100. I will also have to specify the weights and I will also have to specify the sequence length of each input. Since the LSTM layer also accepts word vectors as an input and the word vectors that my embedding layers will produce will have a dimension of hundred, that's why you see hundred as a parameter value over here.\n",
    "Lastly, will be my dense layer with soft Max activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iw2NXo59WIGo"
   },
   "source": [
    "will have to make sure that the embedding layer is non- trainable-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "r2c5GXEEU5dY"
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3XOxGCVLWF0V",
    "outputId": "a6fc3599-9e4a-4f18-b4c8-cd0d511c6a10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 16, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 1,080,804\n",
      "Trainable params: 80,804\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srTGQxT1WaU4"
   },
   "source": [
    "We can see that I have non- trainable parameters which correspond to the weights of the vectors in the embedding layer. I will compile my model. Then I will run my model of the."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "expDDQ8_WU5l"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ObShjC8WUiM",
    "outputId": "95d90804-8c5f-46d4-9246-ef567e910e98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4225/4225 [==============================] - 68s 16ms/step - loss: 0.3784 - accuracy: 0.8618 - val_loss: 0.3269 - val_accuracy: 0.8814\n",
      "Epoch 2/3\n",
      "4225/4225 [==============================] - 64s 15ms/step - loss: 0.2745 - accuracy: 0.9024 - val_loss: 0.2689 - val_accuracy: 0.9057\n",
      "Epoch 3/3\n",
      "4225/4225 [==============================] - 65s 15ms/step - loss: 0.2333 - accuracy: 0.9174 - val_loss: 0.2527 - val_accuracy: 0.9117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faa704ead10>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_features, y_train, epochs=3,batch_size=32,\n",
    "          validation_split=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYZKS6Y4Wvpb"
   },
   "source": [
    "you can see that my validation accuracy is 91%.\n",
    "Let's look at the accuracy of this model on my test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liEFrFJ0WUU3",
    "outputId": "36ce3472-b46d-4bd7-e0f1-27028d73f454"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90876379])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=model.predict(test_features)\n",
    "\n",
    "max_labels = []\n",
    "for i in preds:\n",
    "  max_labels.append(np.argmax(i))\n",
    "\n",
    "pred_labels=enc.inverse_transform(np.array(max_labels))\n",
    "(y_test==pred_labels).sum()/pred_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpyo0onZWxK4"
   },
   "source": [
    "the accuracy on my test data is around 91%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htrBNCT9WyUD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
