{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78ba8803",
   "metadata": {},
   "source": [
    "#### Context\n",
    "Past studies in Sarcasm Detection mostly make use of Twitter datasets collected using hashtag based supervision but such datasets are noisy in terms of labels and language. Furthermore, many tweets are replies to other tweets and detecting sarcasm in these requires the availability of contextual tweets.\n",
    "\n",
    "To overcome the limitations related to noise in Twitter datasets, this News Headlines dataset for Sarcasm Detection is collected from two news website. TheOnion aims at producing sarcastic versions of current events and we collected all the headlines from News in Brief and News in Photos categories (which are sarcastic). We collect real (and non-sarcastic) news headlines from HuffPost.\n",
    "\n",
    "This new dataset has following advantages over the existing Twitter datasets:\n",
    "- Since news headlines are written by professionals in a formal manner, there are no spelling mistakes and informal usage. This reduces the sparsity and also increases the chance of finding pre-trained embeddings.\n",
    "- Furthermore, since the sole purpose of TheOnion is to publish sarcastic news, we get high-quality labels with much less noise as compared to Twitter datasets.\n",
    "- Unlike tweets which are replies to other tweets, the news headlines we obtained are self-contained. This would help us in teasing apart the real sarcastic elements.\n",
    "\n",
    "#### Content\n",
    "Each record consists of three attributes:\n",
    "- is_sarcastic: 1 if the record is sarcastic otherwise 0\n",
    "- headline: the headline of the news article\n",
    "- article_link: link to the original news article. Useful in collecting supplementary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d9cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions/Instructions:\n",
    "\n",
    "# 1. Read the json file named \"Sarcasm_Headlines_Dataset\". Set the parameter lines to bool value True.\n",
    "\n",
    "# 2. Explore the data and analyse what sort of cleaning to be undertaken. Ensure that the text/headlines are valid.\n",
    "#    Also, add additional stopwords if necessary, depending on your results obtained from EDA.\n",
    "\n",
    "# 3. Encode the target variable before doing train-test split.\n",
    "\n",
    "# 4. Tokenize the data and convert the text to sequences. Add padding to ensure that all the sequences have the same shape.\n",
    "#    Set 2000 as the number of unique words to be considered in the corpus and sequence length equal to the number of features \n",
    "#    present in your X after tokenization.\n",
    "\n",
    "# 5. Define your rnn-lstm architecture with embedding layer that will output vectors with dimension 128. Define lstm layer with\n",
    "#    parameter value of 196.\n",
    "\n",
    "# 6. While compiling the model, use categorical cross entropy loss and adam optimizer. Run 25 epochs on batch sizes of 32.\n",
    "\n",
    "# 7. Keep aside a validation set of size 1500 from your test set for further evaluation and then capture \n",
    "#    the loss and accuracy of predictions on the test set. Also, check the accuracy and loss for the validation set kept aside\n",
    "#    for both sarcastic and non-sarcastic headlines.\n",
    "\n",
    "# 8. You may create a new test record, that is headline, to feed into the model and check the prediction given out."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
